{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 2 Enhanced: Cross-Modal Attention Fusion with Tabular Transformer\n",
    "## Intermediate Fusion with Attention Mechanism + Transformer Tabular Encoder\n",
    "\n",
    "This notebook trains an enhanced model with:\n",
    "- **Tabular Transformer**: Self-attention for tabular features (replaces MLP)\n",
    "- **Cross-Modal Attention**: Image-tabular fusion\n",
    "- **Attention Visualization**: GradCAM-style visualizations on validation set\n",
    "\n",
    "### Architecture:\n",
    "1. **Image Branch**: EfficientNet-B1 â†’ Spatial feature maps (7Ã—7Ã—1280)\n",
    "2. **Tabular Branch**: **Transformer Encoder** â†’ Context vector (32-dim) [ENHANCED]\n",
    "3. **Cross-Modal Attention**: Uses tabular context to weight image features\n",
    "4. **Fusion Network**: Concatenated features â†’ Price prediction\n",
    "5. **Visualization**: Attention maps on validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our modules\n",
    "from config import *\n",
    "from attention_model import AttentionFusionModel, count_parameters\n",
    "from dataset import create_dataloaders, prepare_features\n",
    "from train import train_attention_model, load_checkpoint\n",
    "from attention_visualizer import AttentionVisualizer, analyze_attention_patterns\n",
    "\n",
    "print(f\"âœ… Imports successful\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"ðŸ“‚ Loading processed data...\")\n\n# Load data from Approach 1 preprocessing\ntrain_df = pd.read_csv('../data/train_processed.csv')\nval_df = pd.read_csv('../data/val_processed.csv')\ntest_df = pd.read_csv('../data/test_processed.csv')\n\n# Try to load final_test if it exists\ntry:\n    final_test_df = pd.read_csv('../data/final_test_processed.csv')\nexcept FileNotFoundError:\n    print(\"âš ï¸  final_test_processed.csv not found, using test_df instead\")\n    final_test_df = test_df.copy()\n\nprint(f\"\\nðŸ“Š Dataset Sizes:\")\nprint(f\"  Train:      {len(train_df):>6,} rows\")\nprint(f\"  Validation: {len(val_df):>6,} rows\")\nprint(f\"  Test:       {len(test_df):>6,} rows\")\nprint(f\"  Final Test: {len(final_test_df):>6,} rows\")\n\nprint(f\"\\nðŸ“Š Images Available:\")\nfor name, df in [('Train', train_df), ('Validation', val_df), ('Test', test_df), ('Final Test', final_test_df)]:\n    img_count = df['image_exists'].sum()\n    img_pct = 100 * img_count / len(df)\n    print(f\"  {name:12s} {img_count:>6,} ({img_pct:.1f}%)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Tabular Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare feature columns\n",
    "feature_columns, train_df = prepare_features(train_df, {\n",
    "    'NUMERICAL_FEATURES': NUMERICAL_FEATURES,\n",
    "    'CATEGORICAL_FEATURES': CATEGORICAL_FEATURES,\n",
    "    'LOG_FEATURES': LOG_FEATURES,\n",
    "    'EXCLUDE_FEATURES': EXCLUDE_FEATURES\n",
    "})\n",
    "\n",
    "# Ensure all dataframes have the same features\n",
    "for df in [val_df, test_df, final_test_df]:\n",
    "    for feat in feature_columns:\n",
    "        if feat not in df.columns:\n",
    "            df[feat] = 0\n",
    "\n",
    "print(f\"\\nðŸ“Š Final Feature Set: {len(feature_columns)} features\")\n",
    "print(f\"  First 10: {feature_columns[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Update config with actual input dimensions\nconfig_dict = {\n    'IMAGE_CONFIG': IMAGE_CONFIG,\n    'TRANSFORMER_CONFIG': TRANSFORMER_CONFIG,\n    'ATTENTION_CONFIG': ATTENTION_CONFIG,\n    'FUSION_CONFIG': FUSION_CONFIG,\n    'TRAINING_CONFIG': TRAINING_CONFIG,\n    'AUGMENTATION_CONFIG': AUGMENTATION_CONFIG,\n    'VISUALIZATION_CONFIG': VISUALIZATION_CONFIG,\n    'MLFLOW_CONFIG': MLFLOW_CONFIG,\n    'NUM_WORKERS': NUM_WORKERS,\n    'NUMERICAL_FEATURES': NUMERICAL_FEATURES,\n    'CATEGORICAL_FEATURES': CATEGORICAL_FEATURES,\n    'LOG_FEATURES': LOG_FEATURES,\n    'EXCLUDE_FEATURES': EXCLUDE_FEATURES,\n}\n\n# Create dataloaders\ndataloaders, stats = create_dataloaders(\n    train_df, val_df, test_df,\n    feature_columns,\n    config_dict\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize Model with Tabular Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ—ï¸  Initializing Enhanced Attention Fusion Model with Tabular Transformer...\")\n",
    "\n",
    "model = AttentionFusionModel(\n",
    "    tabular_input_dim=len(feature_columns),\n",
    "    config=config_dict\n",
    ").to(DEVICE)\n",
    "\n",
    "# Print model architecture details\n",
    "param_info = count_parameters(model)\n",
    "\n",
    "print(f\"\\nðŸ“Š Model Parameters:\")\n",
    "print(f\"  Total:     {param_info['total']:>12,}\")\n",
    "print(f\"  Trainable: {param_info['trainable']:>12,} ({param_info['trainable_pct']:.1f}%)\")\n",
    "print(f\"  Frozen:    {param_info['frozen']:>12,}\")\n",
    "\n",
    "if 'components' in param_info:\n",
    "    print(f\"\\nðŸ“Š Component Breakdown:\")\n",
    "    for comp_name, comp_params in param_info['components'].items():\n",
    "        print(f\"  {comp_name:30s}: {comp_params:>12,}\")\n",
    "\n",
    "print(f\"\\nâœ… Model initialized successfully!\")\n",
    "print(f\"   Image Backbone: {IMAGE_CONFIG['backbone']}\")\n",
    "print(f\"   Freeze Ratio: {IMAGE_CONFIG['freeze_ratio']}\")\n",
    "print(f\"   Tabular Transformer: d_model={TRANSFORMER_CONFIG['d_model']}, heads={TRANSFORMER_CONFIG['nhead']}, layers={TRANSFORMER_CONFIG['num_layers']}\")\n",
    "print(f\"   Cross-Attention Heads: {ATTENTION_CONFIG['attention_heads']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trained_model, history, best_metrics = train_attention_model(\n",
    "    model=model,\n",
    "    dataloaders=dataloaders,\n",
    "    stats=stats,\n",
    "    config=config_dict,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸŽ‰ TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Loss\n",
    "axes[0, 0].plot(history['train_loss'], label='Train', linewidth=2)\n",
    "axes[0, 0].plot(history['val_loss'], label='Validation', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Loss (MSE)', fontsize=12)\n",
    "axes[0, 0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].legend(fontsize=11)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# RMSE\n",
    "axes[0, 1].plot(history['train_rmse'], label='Train', linewidth=2)\n",
    "axes[0, 1].plot(history['val_rmse'], label='Validation', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 1].set_ylabel('RMSE ($)', fontsize=12)\n",
    "axes[0, 1].set_title('Training and Validation RMSE', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].legend(fontsize=11)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# RÂ²\n",
    "axes[1, 0].plot(history['train_r2'], label='Train', linewidth=2)\n",
    "axes[1, 0].plot(history['val_r2'], label='Validation', linewidth=2)\n",
    "axes[1, 0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1, 0].set_ylabel('RÂ² Score', fontsize=12)\n",
    "axes[1, 0].set_title('Training and Validation RÂ²', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].legend(fontsize=11)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning Rate\n",
    "axes[1, 1].plot(history['learning_rate'], linewidth=2, color='green')\n",
    "axes[1, 1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Learning Rate', fontsize=12)\n",
    "axes[1, 1].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_yscale('log')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nðŸ“Š Training history plot saved to: ../reports/training_history.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. [NEW] Attention Visualizations on Validation Set\n",
    "\n",
    "Generate attention heatmaps to understand what the model focuses on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸŽ¨ Generating Attention Visualizations...\")\n",
    "\n",
    "# Load best model\n",
    "checkpoint = load_checkpoint()\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Create visualizer\n",
    "visualizer = AttentionVisualizer(model, DEVICE)\n",
    "\n",
    "# Generate visualizations for validation samples\n",
    "viz_dir = VISUALIZATION_CONFIG['save_dir']\n",
    "viz_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "visualizations = visualizer.visualize_batch(\n",
    "    dataloaders['val'],\n",
    "    num_samples=VISUALIZATION_CONFIG['num_samples'],\n",
    "    save_dir=viz_dir\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Attention visualizations saved to: {viz_dir}\")\n",
    "print(f\"   Open these images to see what the model attends to!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. [NEW] Analyze Attention Patterns\n",
    "\n",
    "Compute statistics about attention behavior across the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ“Š Analyzing Attention Patterns Across Validation Set...\")\n",
    "\n",
    "attention_analysis = analyze_attention_patterns(\n",
    "    model, dataloaders['val'], DEVICE, stats,\n",
    "    num_samples=VISUALIZATION_CONFIG['num_analysis_samples']\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸ“ˆ Attention Pattern Analysis:\")\n",
    "print(f\"  Mean Entropy: {attention_analysis['mean_entropy']:.4f} Â± {attention_analysis['std_entropy']:.4f}\")\n",
    "print(f\"  Mean Max Attention: {attention_analysis['mean_max_attention']:.4f}\")\n",
    "print(f\"\\n  Head-wise Mean Activations:\")\n",
    "for i, activation in enumerate(attention_analysis['head_activations_mean']):\n",
    "    print(f\"    Head {i+1}: {activation:.4f}\")\n",
    "\n",
    "# Plot head activation distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "heads = np.arange(len(attention_analysis['head_activations_mean']))\n",
    "plt.bar(heads, attention_analysis['head_activations_mean'], \n",
    "        yerr=attention_analysis['head_activations_std'],\n",
    "        alpha=0.7, capsize=5)\n",
    "plt.xlabel('Attention Head', fontsize=12)\n",
    "plt.ylabel('Mean Activation', fontsize=12)\n",
    "plt.title('Attention Head Activation Distribution', fontsize=14, fontweight='bold')\n",
    "plt.xticks(heads, [f'H{i+1}' for i in heads])\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig(viz_dir / 'attention_head_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nâœ… Attention analysis plot saved to: {viz_dir / 'attention_head_distribution.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "**Enhanced Model with:**\n",
    "1. âœ… Tabular Transformer replacing MLP\n",
    "2. âœ… Cross-modal attention mechanism\n",
    "3. âœ… Attention visualizations saved\n",
    "4. âœ… Attention pattern analysis completed\n",
    "\n",
    "**Next Steps:**\n",
    "- Review attention visualizations in `reports/attention_visualizations/`\n",
    "- Analyze which image regions the model focuses on\n",
    "- Compare results with Approach 1\n",
    "- Consider Approach 3 based on learnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸŽ‰ NOTEBOOK EXECUTION COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nðŸ“Š Best Validation Metrics:\")\n",
    "print(f\"  RMSE: ${best_metrics['rmse']:>12,.2f}\")\n",
    "print(f\"  RÂ²:   {best_metrics['r2']:>8.4f}\")\n",
    "print(f\"  MAE:  ${best_metrics['mae']:>12,.2f}\")\n",
    "print(f\"\\nðŸ’¾ Model saved to: {MODELS_DIR / 'best_attention_model.pth'}\")\n",
    "print(f\"ðŸŽ¨ Visualizations saved to: {viz_dir}\")\n",
    "print(f\"\\nðŸ‘€ Check the visualizations to see what the model learned to attend to!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}